<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>机器学习ML2 | Strider's blog</title><meta name="author" content="Strider"><meta name="copyright" content="Strider"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="CNN神经网络分类器1.实验目的​    实验的主要目的是使用CNN架构实现一个神经网络图像分类器，能够将网络上收集到的食物图片分为11类，并对模型架构、训练参数量和准确率进行评估。通过尝试对CNN深度进行改变来比较模型训练的效果，并尝试用data normalization和data augmentation来优化模型。 2.实验环境kaggle；python 3.9 3.实验方法3.1 预处理">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习ML2">
<meta property="og:url" content="http://example.com/2022/12/08/ML3/index.html">
<meta property="og:site_name" content="Strider&#39;s blog">
<meta property="og:description" content="CNN神经网络分类器1.实验目的​    实验的主要目的是使用CNN架构实现一个神经网络图像分类器，能够将网络上收集到的食物图片分为11类，并对模型架构、训练参数量和准确率进行评估。通过尝试对CNN深度进行改变来比较模型训练的效果，并尝试用data normalization和data augmentation来优化模型。 2.实验环境kaggle；python 3.9 3.实验方法3.1 预处理">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://images.pexels.com/photos/789380/pexels-photo-789380.jpeg?auto=compress&cs=tinysrgb&w=1600">
<meta property="article:published_time" content="2022-12-08T14:08:52.000Z">
<meta property="article:modified_time" content="2023-01-06T03:50:25.840Z">
<meta property="article:author" content="Strider">
<meta property="article:tag" content="神经网络分类器 CNN">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://images.pexels.com/photos/789380/pexels-photo-789380.jpeg?auto=compress&cs=tinysrgb&w=1600"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2022/12/08/ML3/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"We didn't find any results for the search: ${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '机器学习ML2',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-01-06 11:50:25'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.2"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">Loading...</div></div></div><script>const preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> { preloader.endLoading() })

if (false) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/header.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">46</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">23</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">13</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://images.pexels.com/photos/789380/pexels-photo-789380.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=1600')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Strider's blog</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> Search</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">机器学习ML2</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2022-12-08T14:08:52.000Z" title="Created 2022-12-08 22:08:52">2022-12-08</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-01-06T03:50:25.840Z" title="Updated 2023-01-06 11:50:25">2023-01-06</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Machine-Learning/">Machine Learning</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="机器学习ML2"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="CNN神经网络分类器"><a href="#CNN神经网络分类器" class="headerlink" title="CNN神经网络分类器"></a><centering>CNN神经网络分类器</centering></h1><h3 id="1-实验目的"><a href="#1-实验目的" class="headerlink" title="1.实验目的"></a>1.实验目的</h3><p>​    实验的主要目的是使用CNN架构实现一个神经网络图像分类器，能够将网络上收集到的食物图片分为11类，并对模型架构、训练参数量和准确率进行评估。通过尝试对CNN深度进行改变来比较模型训练的效果，并尝试用data normalization和data augmentation来优化模型。</p>
<h3 id="2-实验环境"><a href="#2-实验环境" class="headerlink" title="2.实验环境"></a>2.实验环境</h3><p>kaggle；python 3.9</p>
<h3 id="3-实验方法"><a href="#3-实验方法" class="headerlink" title="3.实验方法"></a>3.实验方法</h3><h4 id="3-1-预处理"><a href="#3-1-预处理" class="headerlink" title="3.1 预处理"></a>3.1 预处理</h4><h5 id="3-1-1-文件读取"><a href="#3-1-1-文件读取" class="headerlink" title="3.1.1 文件读取"></a>3.1.1 文件读取</h5><p>​    首先对训练文件进行读取，在读取文件时，我们将每一个照片读取成128*128像素，3RGB的图片，这里对文件读取时采用cv2模块，另外对训练集、验证集和测试集要加以区分，因为训练集和验证集的数据有图像对应分类真实label。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">readfile</span>(<span class="params">path, label</span>):</span><br><span class="line">    <span class="comment"># label 是一个 boolean variable</span></span><br><span class="line">    image_dir = <span class="built_in">sorted</span>(os.listdir(path))</span><br><span class="line">    <span class="comment">#获取path下的文件名列表</span></span><br><span class="line">    x = np.zeros((<span class="built_in">len</span>(image_dir), <span class="number">128</span>, <span class="number">128</span>, <span class="number">3</span>), dtype=np.uint8)</span><br><span class="line">    <span class="comment">#输入数据集的大小，其中每一个样本是一个128*128*3的样本图片</span></span><br><span class="line">    y = np.zeros((<span class="built_in">len</span>(image_dir)), dtype=np.uint8)</span><br><span class="line">    <span class="comment">#y是对应每一个样本的输出值</span></span><br><span class="line">    <span class="keyword">for</span> i, file <span class="keyword">in</span> <span class="built_in">enumerate</span>(image_dir):</span><br><span class="line">        img = cv2.imread(os.path.join(path, file))</span><br><span class="line">        <span class="comment">#使用cv2.imread读入一张图片</span></span><br><span class="line">        x[i, :, :] = cv2.resize(img,(<span class="number">128</span>, <span class="number">128</span>))</span><br><span class="line">        <span class="comment">#将原图片转化为128*128的图片</span></span><br><span class="line">        <span class="keyword">if</span> label:</span><br><span class="line">          y[i] = <span class="built_in">int</span>(file.split(<span class="string">&quot;_&quot;</span>)[<span class="number">0</span>])</span><br><span class="line">        <span class="comment">#如果图片标签中有_说明是train或者validation有分类的数据</span></span><br><span class="line">    <span class="keyword">if</span> label:</span><br><span class="line">      <span class="keyword">return</span> x, y</span><br><span class="line">    <span class="comment">#如果有label就区分为x和y</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">return</span> x</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h5 id="3-1-2-data-augmentation"><a href="#3-1-2-data-augmentation" class="headerlink" title="3.1.2 data augmentation"></a>3.1.2 data augmentation</h5><p>​    数据增强主要用于在dataset比较小的时候防止过拟合，随着神经网络的深度增加，数据集过小的时候，过多的参数会拟合数据的所有特点，而非数据之间的共性，那么模型就会缺乏泛化能力，而数据增强由于增加了噪声和变化，能够让模型更好的提取共性，从而防止过拟合的发生。数据增强的左右可以总结为下点：</p>
<ol>
<li>增加训练的数据量，提高模型的泛化能力</li>
<li>增加噪声数据，提升模型的鲁棒性</li>
<li>一定程度上能解决过拟合问题，样本过少容易出现过拟合</li>
<li>解决样本不平衡问题，例如某个类别过少，数据增强可以增强这个类别的数量。</li>
</ol>
<p>​    对于一个卷积神经网络，如果能够对物体即使它放在不同的地方也能够进行稳健的分类，就被称为具有不变性的属性。更具体的，CNN可以对移位(translation)、视角(viewpoint)、大小(size)、照明(illumination)等具有不变性。</p>
<p>​    下面是几种常见的数据增强方法：</p>
<p>1.随机旋转<br>随机旋转一般情况下是对输入图像随机旋转[0,360)<br>2.随机裁剪<br>随机裁剪是对输入图像随机切割掉一部分<br>3.色彩抖动<br>色彩抖动指的是在颜色空间如RGB中，每个通道随机抖动一定的程度。在实际的使用中，该方法不常用，在很多场景下反而会使实验结果变差<br>4.高斯噪声<br>是指在图像中随机加入少量的噪声。该方法对防止过拟合比较有效，这会让神经网络不能拟合输入图像的所有特征<br>5.水平翻转<br>6.竖直翻转</p>
<p>​    在模型训练中，我们可以用pytorch中的transform方法来进行data augmentation，但是并不是每一种augmentation对当前模型训练都有正向作用，这需要我们进行尝试。<a target="_blank" rel="noopener" href="https://pytorch.org/vision/stable/transforms.html">转换和增强图像 — Torchvision 0.14 文档 (pytorch.org)</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># training 時做 data augmentation</span></span><br><span class="line">train_transform = transforms.Compose([</span><br><span class="line">    transforms.ToPILImage(),</span><br><span class="line">    <span class="comment">#将张量转为PIL图片，由小数转为0-255之间的像素值</span></span><br><span class="line">    transforms.RandomHorizontalFlip(),<span class="comment">#随机将图片进行水平翻转</span></span><br><span class="line">    transforms.RandomRotation(<span class="number">15</span>), <span class="comment">#随机旋转图片</span></span><br><span class="line">    transforms.ToTensor(), <span class="comment">#将图片转成Tensor，并把数值normalize到[0,1](data normalization)</span></span><br><span class="line">])</span><br><span class="line"><span class="comment"># testing 時不需做 data augmentation</span></span><br><span class="line">test_transform = transforms.Compose([</span><br><span class="line">    transforms.ToPILImage(),                                    </span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<h5 id="3-1-3-类型转化"><a href="#3-1-3-类型转化" class="headerlink" title="3.1.3 类型转化"></a>3.1.3 类型转化</h5><p>​    流程是先把原始数据转变成 torch.utils.data.Dataset类随后再把得到的torch.utils.data.Dataset类<br>当作一个参数传递给  torch.utils.data.DataLoader类，得到一个数据加载器，这个数据加载器每次可以返回<br>一个 Batch 的数据供模型训练使用。</p>
<p>​    这里 torch.utils.data.Dataset是一个抽象类，用户想要加载自定义的数据只需要继承这个类，并且覆写其中的两个方法即可：</p>
<p>1.__len__:实验len(dataset)返回整个数据集的大小</p>
<p>2.__getitem__用来获取一些索引的数据，使dataset[i]返回数据集中的第i个样本</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ImgDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, x, y=<span class="literal">None</span>, transform=<span class="literal">None</span></span>):</span><br><span class="line">        self.x = x</span><br><span class="line">        <span class="comment"># label is required to be a LongTensor</span></span><br><span class="line">        self.y = y</span><br><span class="line">        <span class="keyword">if</span> y <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            self.y = torch.LongTensor(y)<span class="comment">#将数据y转化为longtensor类型</span></span><br><span class="line">        self.transform = transform</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):<span class="comment">#返回自定义数据集的大小</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.x)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, index</span>):<span class="comment">#支持下标访问</span></span><br><span class="line">        X = self.x[index]</span><br><span class="line">        <span class="keyword">if</span> self.transform <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            X = self.transform(X)</span><br><span class="line">        <span class="keyword">if</span> self.y <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            Y = self.y[index]</span><br><span class="line">            <span class="keyword">return</span> X, Y</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> X</span><br><span class="line">        batch_size = <span class="number">128</span></span><br><span class="line">train_set = ImgDataset(train_x, train_y, train_transform)</span><br><span class="line">val_set = ImgDataset(val_x, val_y, test_transform)</span><br><span class="line">train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#batch_size是每次迭代的数量，shuffle是每次epoch是否进行重排</span></span><br><span class="line">val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<p>​    在dataloader中，需要给出一个合适的Batch size，合适的Batch size能够让模型更好的进行梯度下降，但是还需要考虑GPU资源的大小。</p>
<h4 id="3-2神经网络分类器架构"><a href="#3-2神经网络分类器架构" class="headerlink" title="3.2神经网络分类器架构"></a>3.2神经网络分类器架构</h4><p>​    下图为CNN的整体架构，主要分为</p>
<ul>
<li>Convolution</li>
<li>Max Pooling</li>
<li>Flatten</li>
</ul>
<p>​                                  <img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/image-20221121164040095.png" alt="image-20221121164040095" style="zoom:67%;" /></p>
<h5 id="3-2-1-Convolution"><a href="#3-2-1-Convolution" class="headerlink" title="3.2.1 Convolution"></a>3.2.1 Convolution</h5><p>​    Convolution是卷积层，就是使用卷积核对image进行步长为strider的平移，依次于image对应的小矩阵中的元素计算内积，假设你有一张128x128的image，你用n个3x3的Filter去对它做convolution，那么你会得到nx126x126的cube(无padding)，多少个Filter就会有多少层。对于RGB三色图，有R、G、B三个通道，所以就等于输入了三张图片，那么相应的filter就会变为3维3x3x3，filter的厚度对应图片的厚度，那么最终filter过滤后的矩阵就是RGB三个通道位置内积和。</p>
<p>​    <img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/cf5cb5a3e2553f3d74e5a98267d9b2ab.gif" alt="在这里插入图片描述" style="zoom:67%;" /></p>
<p>​        卷积层的作用是对局部的小特征进行提取，filter中的参数是需要network进行学习的，采用strider=1能够防止两个矩阵交界出的feature被遗漏，能够对整个image进行充分的遍历。其中一个filter对应的是一种pattern，一个神经网络中一般需要加入很多filter来提取不同的特征，原图和许多filter计算以后就会得到feature map。</p>
<p>​        通过covolution能够实现两个特性，一是能够从全图中提取一些小的特征，二是能够将不同区域的相同特征提取出来，和全连接神经网络相比，使用filter的做法能够减少参数的使用，因为对于一个3*3的filter，只和原图片中一个小矩阵有关。</p>
<p><img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/image-20221121170829432.png" alt="image-20221121170829432" style="zoom:67%;" /></p>
<p>​    另外，在全连接层中不同神经元使用的参数是不同的，而filter的做法能够使用共享的参数，所以参数量再次减少。</p>
<p><img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/image-20221121170957868.png" alt="image-20221121170957868" style="zoom:67%;" /></p>
<p>在pytorch中，可以使用下面的函数来实现卷积层</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.Conv2d(in_channels=<span class="number">3</span>, out_channels=<span class="number">64</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>in_channels表示的是输入卷积层的图片厚度</li>
<li>out_channels表示的是输出的厚度，也就是filter的数目</li>
<li>kernel_size表示的是卷积核的大小，也就是filter的大小，可以用一个数字表示长宽相等的卷积核， 也可以用不同的数据来表示长宽不同的卷积核，比如kernel_size=(3,2)</li>
<li>strider表示的是卷积核滑动的步长</li>
<li>padding是在图片周围补充0，padding=0表示不填充,padding=1表示填充一维这样就可以将提取范围扩展 到更加边界的区域，如前两行，其中前面一行已经预先填入了0</li>
</ul>
</blockquote>
<h5 id="3-2-2-Maxpooling"><a href="#3-2-2-Maxpooling" class="headerlink" title="3.2.2 Maxpooling"></a>3.2.2 Maxpooling</h5><p>​    Maxpooling (池化层)，Maxpooling的作用是减少像素点的个数，这样对图片的影响不会太大，但是能将训练数据的个数大大减少。</p>
<p><img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/image-20221121171924114.png" alt="image-20221121171924114" style="zoom: 67%;" /></p>
<p>​    在pytorch中Maxpooling可以用以下的函数进行实现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nn.MaxPool2d(kernel_size =<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<blockquote>
<p> nn.MaxPool2d(kernel_size =2, stride=2, padding=0)<br>池化层，也就是根据kernel_size和strider,对convolution得到的cube区域进行分割并取区域的最大值</p>
</blockquote>
<p>在经过第一次convlution和Max pooling之后，image变为了2x2，2 layer的cube，再次经过上述过程后，image的layer不会增加，始终为filter的数目，这是因为下一次convolution时会考虑image-cube的深度。</p>
<h5 id="3-2-3-CNN完整结构"><a href="#3-2-3-CNN完整结构" class="headerlink" title="3.2.3 CNN完整结构"></a>3.2.3 CNN完整结构</h5><p>​    经过一次Convolution和Max Pooling等于学习到了更小的，并提取关键特征的图片，这样的过程可以进行循环迭代多次，然后展平flatten送入全连接神经网络进行训练。</p>
<p><img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/image-20221121192343694.png" alt="image-20221121192343694" style="zoom:67%;" /></p>
<p>​    在pytorch中，我们可以使用nn.sequential来实现这个过程， nn.sequential()是一个序列容器，用于搭建神经网络的模块按照被传入构造器的顺序添加到nn.sequential()中，利用nn.Sequential()搭建好模型架构，模型前向传播时调用forward()方法，模型接收的输入首先被传入nn.Sequential()包含的第一个网络模块中。然后，第一个网络模块的输出传入第二个 网络模块作为输入，按照顺序依次计算并传播，直到nn.Sequential()里的最后一个模块输出结果。</p>
<p>​    与一层一层的单独调用模块组成序列相比，nn.Sequential() 可以允许将整个容器视为单个模块（即相当于把多个模块封装成一个模块），forward()方法接收输入之后，nn.Sequential()按照内部模块的顺序自动依次计算并输出结果。具体的实现过程如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">self.cnn = nn.Sequential(</span><br><span class="line">      nn.Conv2d(in_channels=<span class="number">3</span>, out_channels=<span class="number">64</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">      nn.BatchNorm2d(<span class="number">64</span>),<span class="comment"># 归一化处理,参数是64</span></span><br><span class="line">      nn.ReLU(),</span><br><span class="line">      nn.MaxPool2d(kernel_size =<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>),   </span><br><span class="line">      <span class="comment">#由于padding了前后两列0，并且kernel大小为3，其实filter过滤后图片并无减小，减小只是在</span></span><br><span class="line">      <span class="comment">#maxpool池化，[64,64,64]64是filter，image-map</span></span><br><span class="line">      </span><br><span class="line">      </span><br><span class="line">      nn.Conv2d(<span class="number">64</span>,<span class="number">128</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>),</span><br><span class="line">      <span class="comment">#[128,64,64]这里我们取128个卷积核</span></span><br><span class="line">      nn.BatchNorm2d(<span class="number">128</span>),</span><br><span class="line">      nn.ReLU(),</span><br><span class="line">      nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>,<span class="number">0</span>),</span><br><span class="line">      <span class="comment">#[128,32,32]</span></span><br><span class="line">      </span><br><span class="line">      nn.Conv2d(<span class="number">128</span>,<span class="number">256</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>),</span><br><span class="line">      <span class="comment">#[256,32,32]这里我们取256个卷积核</span></span><br><span class="line">      nn.BatchNorm2d(<span class="number">256</span>),</span><br><span class="line">      nn.ReLU(),</span><br><span class="line">      nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>,<span class="number">0</span>),</span><br><span class="line">      <span class="comment">#[256,16,16]</span></span><br><span class="line"></span><br><span class="line">      nn.Conv2d(<span class="number">256</span>,<span class="number">512</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>),</span><br><span class="line">      <span class="comment">#[512,16,16]这里我们取512个卷积核</span></span><br><span class="line">      nn.BatchNorm2d(<span class="number">512</span>),</span><br><span class="line">      nn.ReLU(),</span><br><span class="line">      nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>,<span class="number">0</span>),</span><br><span class="line">      <span class="comment">#[512,8,8]</span></span><br><span class="line">      </span><br><span class="line">      nn.Conv2d(<span class="number">512</span>,<span class="number">512</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>),</span><br><span class="line">      <span class="comment">#[512,8,8]这里我们取512个卷积核</span></span><br><span class="line">      nn.BatchNorm2d(<span class="number">512</span>),</span><br><span class="line">      nn.ReLU(),</span><br><span class="line">      nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>,<span class="number">0</span>),</span><br><span class="line">      <span class="comment">#[512,4,4]#最后输出的cube，之后展开为全连接网络</span></span><br><span class="line">      </span><br><span class="line">  )</span><br></pre></td></tr></table></figure>
<p>​    这里卷积核取的越来越多，这里是将小特征逐步进行汇总成更多的大特征来对图像进行处理。</p>
<h4 id="3-3-全连接神经网络"><a href="#3-3-全连接神经网络" class="headerlink" title="3.3 全连接神经网络"></a>3.3 全连接神经网络</h4><h5 id="3-3-1-全连接层"><a href="#3-3-1-全连接层" class="headerlink" title="3.3.1 全连接层"></a>3.3.1 全连接层</h5><p>​    下面的过程我们将展平后的数据放入全连接神经网络中进行训练，在全连接神经网络中，我们逐步减小hiding layer中神经元的数量，也就是逐步细化分类，最终输出11种food分类的结果。</p>
<p>​    在pytorch中，我们可以使用nn.linear来设置网络中的全连接层，在全连接层的输入与输出都是二维张量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.Linear(in_features,out_features,bias=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>in_feature:上层神经元的个数，输入样本的大小</li>
<li>out_feature:本层神经元的个数，也就是输出样本的大小</li>
<li>​    bias:偏置，如果为false就不会学习附加偏置</li>
</ul>
</blockquote>
<h5 id="3-3-2-激活函数"><a href="#3-3-2-激活函数" class="headerlink" title="3.3.2 激活函数"></a>3.3.2 激活函数</h5><p>​    在数据通过全连接层后，然后会通过激活函数，这里我们采用的是ReLU函数，相比与sigmoid函数，能够在深度比较大的网络中处理梯度消失的问题。在sigmoid函数中，由于强制的将值域压制在0和1之间，当sigmoid接近饱和区时，梯度就会趋近于0，在深度网络中，经过这样层层的压缩，最初w的增量就无法传播到最后的输出值上，也就会在梯度下降中出现梯度消失的情况。</p>
<p>​    而ReLU函数会使一部分神经元的输出为0，这样就造成了网络的稀疏性，并减少了参数之间相互依存，缓解了过拟合现象。另外求导不涉及除法，反向传播简单。ReLU函数的引入并不改变激活函数的非线性特性，虽然在最终训练结果上好像是线性存在的，但是ReLU函数是一个分段函数，在没有训练完成的情况下，整个模型仍然有非线性存在。</p>
<p><img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/image-20221121201641639.png" alt="image-20221121201641639" style="zoom:67%;" /></p>
<p><img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/241900156879853.png" alt="img" style="zoom:67%;" /></p>
<p>在pytorch中可以直接使用下面的语句进行激活函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.ReLU()</span><br></pre></td></tr></table></figure>
<h5 id="3-3-3-完整的全连接神经网络"><a href="#3-3-3-完整的全连接神经网络" class="headerlink" title="3.3.3 完整的全连接神经网络"></a>3.3.3 完整的全连接神经网络</h5><p>​    在forward函数是正向进行整个的训练过程，输入x[[batch_size, 3, 128, 128]],输出[batch_size, 11]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">    self.fc = nn.Sequential(</span><br><span class="line">        nn.Linear(<span class="number">512</span>*<span class="number">4</span>*<span class="number">4</span>,<span class="number">1024</span>),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Linear(<span class="number">1024</span>,<span class="number">512</span>),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Linear(<span class="number">512</span>,<span class="number">11</span>)<span class="comment">#11个类别，11中输出</span></span><br><span class="line">    )</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">    out = self.cnn(x)</span><br><span class="line">    out = out.view(out.size()[<span class="number">0</span>], -<span class="number">1</span>)</span><br><span class="line">    <span class="comment">#flatten the feature map</span></span><br><span class="line">    <span class="keyword">return</span> self.fc(out)</span><br></pre></td></tr></table></figure>
<h4 id="3-4-模型训练"><a href="#3-4-模型训练" class="headerlink" title="3.4 模型训练"></a>3.4 模型训练</h4><p>​    下面我们进行模型训练的过程，这里我们可以使用GPU对模型训练进行加速</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">model = Classifier().cuda()</span><br><span class="line"><span class="comment">#将模型加载到GPU上进行计算</span></span><br></pre></td></tr></table></figure>
<p>​    这里我们梯度下降过程使用Adam优化器进行实现，它是目前认为最好的梯度下降算法。</p>
<p>​    在模型训练中，不同方向的gradient是不同的，使用Adagrad的方式，能够对不同的方向给出不同的学习率（用二阶导数来逼近最佳步长），在深度学习中，梯度将变得复杂，因此我们要用更新的方式进行优化。在Adagrad中，我们知道Adagrad的learning rate是所有gradient的均方根，而在RMSProp中，梯度的均方根将加入一个权重系数，<img src="https://private.codecogs.com/gif.latex?%5Calpha" alt="\alpha">越小，代表越倾向于相信此时算出来的新的gradient所告诉你的error surface的陡峭程度；而<img src="https://private.codecogs.com/gif.latex?%5Calpha" alt="\alpha">越大，则代表越倾向于相信以往算出来的gradient 。</p>
<p><img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/image-20221121202449706.png" alt="image-20221121202449706" style="zoom:67%;" /></p>
<p>​    另一个优化方式是在梯度下降中加入冲量， 现实世界中，一个球由高处往地处走，到达最低点后并不会直接停下来，可能会由于惯性的影响再移动一点。所以就想到把惯性的因素也考虑进gradient descent里面，就不会因为遇到local minima而直接卡主。</p>
<p>​                                     <img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/image-20221121202507013.png" alt="image-20221121202507013" style="zoom:67%;" /></p>
<p>​    因此我们就可以在梯度下降过程中加入一些上一个梯度的权重，让上一步的移动对下一步的移动产生纠正，当权重设置的合理时，也许函数就能够越过局部最低点或者平地(只是一种可能)。</p>
<p><img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/20200218170852194.png" alt="img" style="zoom:67%;" /></p>
<p> 把刚才讲的RMSProp 和 Momentum 结合起来，就形成Adam，具体在pytorch中的训练过程如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">model = Classifier().cuda()</span><br><span class="line"><span class="comment">#将模型加载到GPU上进行计算</span></span><br><span class="line">loss = nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment"># 因為、为是 classification task，所以 loss 使用 CrossEntropyLoss</span></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">0.001</span>) </span><br><span class="line"><span class="comment"># optimizer 使用 Adam优化器</span></span><br><span class="line">num_epoch = <span class="number">30</span></span><br><span class="line"><span class="comment">#epoch回合迭代的次数是30</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epoch):</span><br><span class="line">    epoch_start_time = time.time()</span><br><span class="line">    train_acc = <span class="number">0.0</span></span><br><span class="line">    train_loss = <span class="number">0.0</span></span><br><span class="line">    val_acc = <span class="number">0.0</span></span><br><span class="line">    val_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    model.train() <span class="comment"># 確保 model 是在 train model </span></span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):<span class="comment">#这里每次训练一个batchsize的量进行梯度下降</span></span><br><span class="line">        optimizer.zero_grad() <span class="comment">#用optimizer将梯度下降中的梯度初始化为0</span></span><br><span class="line">        train_pred = model(data[<span class="number">0</span>].cuda()) <span class="comment">#data[0].cuda是将训练数据x放到GPU上</span></span><br><span class="line">        <span class="comment">#利用module得到预测的概率，其实就是调用module的forward函数</span></span><br><span class="line">        batch_loss = loss(train_pred, data[<span class="number">1</span>].cuda()) </span><br><span class="line">        <span class="comment">#将Y真实值从cpu加载到GPU上，然后利用交叉熵计算loss损失值</span></span><br><span class="line">        batch_loss.backward() </span><br><span class="line">        <span class="comment">#计算loss函数的反向梯度，也就是利用反向传播计算gradient</span></span><br><span class="line">        optimizer.step() </span><br><span class="line">        <span class="comment">#用Adam梯度下降，也就是optimizer更新参数值</span></span><br><span class="line">        train_acc += np.<span class="built_in">sum</span>(np.argmax(train_pred.cpu().data.numpy(), axis=<span class="number">1</span>) == data[<span class="number">1</span>].numpy())</span><br><span class="line">        <span class="comment">#将预测准确的数据量加起来。np.argmax用于返回一个numpy数组中最大值的索引值</span></span><br><span class="line">        train_loss += batch_loss.item()</span><br><span class="line">        <span class="comment">#将计算的loss加入到损失函数序列中</span></span><br><span class="line">    </span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    <span class="comment">#主要是针对model 在训练时和评价时不同的 Batch Normalization 和 Dropout 方法模式</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="comment">#不存储中间过程，不计算梯度</span></span><br><span class="line">        <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(val_loader):</span><br><span class="line">            val_pred = model(data[<span class="number">0</span>].cuda())</span><br><span class="line">            batch_loss = loss(val_pred, data[<span class="number">1</span>].cuda())</span><br><span class="line"></span><br><span class="line">            val_acc += np.<span class="built_in">sum</span>(np.argmax(val_pred.cpu().data.numpy(), axis=<span class="number">1</span>) == data[<span class="number">1</span>].numpy())</span><br><span class="line">            val_loss += batch_loss.item()</span><br><span class="line"></span><br><span class="line">        <span class="comment">#把結果 print 出來</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f | Val Acc: %3.6f loss: %3.6f&#x27;</span> % \</span><br><span class="line">            (epoch + <span class="number">1</span>, num_epoch, time.time()-epoch_start_time, \</span><br><span class="line">             train_acc/train_set.__len__(), train_loss/train_set.__len__(), val_acc/val_set.__len__(), val_loss/val_set.__len__()))</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;得到好的参数后，使用 training set 和 validation set 共同训练&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h4 id="3-5-结果预测"><a href="#3-5-结果预测" class="headerlink" title="3.5 结果预测"></a>3.5 结果预测</h4><p>​    得到参数以后我们再将train和vaildation set进行拼接训练，最后将数据预测输出到文件里，这里要解释一下dataloader里的enumerate方法，这里每个i对应一个batch_size而不是一个数据。完成的过程如下，具体解释已在注释中给出：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">train_val_x = np.concatenate((train_x, val_x), axis=<span class="number">0</span>)  <span class="comment">#将train_set和vailidation_set按行进行拼接</span></span><br><span class="line"><span class="comment">#这里拼接的结果是train_x第一个维度因为拼接扩大其他维度不变，train_y仍然保持一维的大小</span></span><br><span class="line">train_val_y = np.concatenate((train_y, val_y), axis=<span class="number">0</span>)  <span class="comment">#将train_y和vailidation_y按行进行拼接</span></span><br><span class="line">train_val_set = ImgDataset(train_val_x, train_val_y, train_transform)  <span class="comment">#将合并后的x用trian_trainsform方法转化为Dataset</span></span><br><span class="line"></span><br><span class="line">train_val_loader = DataLoader(train_val_set, batch_size=batch_size, shuffle=<span class="literal">True</span>)  <span class="comment">#将合并后dataset按batchsize转化为Dataloader并进行数据重排</span></span><br><span class="line"></span><br><span class="line">model_best = Classifier().cuda()  <span class="comment">#将模型的所有参数和缓存移动到GPU上</span></span><br><span class="line">loss = nn.CrossEntropyLoss()   <span class="comment">#用交叉熵的方法计算损失函数</span></span><br><span class="line">optimizer = torch.optim.Adam(model_best.parameters(), lr=<span class="number">0.001</span>)   <span class="comment">#用Adam方法优化梯度下降函数将学习率定位0.001</span></span><br><span class="line"><span class="comment">#model_best.parameters用于更新参数信息</span></span><br><span class="line">num_epoch = <span class="number">30</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epoch):</span><br><span class="line">    epoch_start_time = time.time()</span><br><span class="line">    train_acc = <span class="number">0.0</span></span><br><span class="line">    train_loss = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line">    model_best.train()</span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_val_loader):</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        train_pred = model_best(data[<span class="number">0</span>].cuda())  <span class="comment">#将train_data放入模型中，并利用模型得到预测的概率分布，其实就是调用model的forward方法</span></span><br><span class="line">        batch_loss = loss(train_pred, data[<span class="number">1</span>].cuda())  <span class="comment">#用y的真实值和预测值按交叉熵的方式计算损失</span></span><br><span class="line">        batch_loss.backward()  <span class="comment">#反向传播计算更新gradient</span></span><br><span class="line">        optimizer.step()  <span class="comment">#用optimizer，也就是Adam梯度优化更新参数值</span></span><br><span class="line"></span><br><span class="line">        train_acc += np.<span class="built_in">sum</span>(np.argmax(train_pred.cpu().data.numpy(), axis=<span class="number">1</span>) == data[<span class="number">1</span>].numpy())</span><br><span class="line">        train_loss += batch_loss.item()</span><br><span class="line"></span><br><span class="line">        <span class="comment">#將結果 print 出來</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;[%03d/%03d] %2.2f sec(s) Train Acc: %3.6f Loss: %3.6f&#x27;</span> % \</span><br><span class="line">      (epoch + <span class="number">1</span>, num_epoch, time.time()-epoch_start_time, \</span><br><span class="line">      train_acc/train_val_set.__len__(), train_loss/train_val_set.__len__()))</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;# Testing</span></span><br><span class="line"><span class="string">利用刚刚 train 好的 model 进行 prediction</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">test_set = ImgDataset(test_x, transform=test_transform)</span><br><span class="line"><span class="comment">#将text_x按test_transform处理为Dataset</span></span><br><span class="line">test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=<span class="literal">False</span>)</span><br><span class="line"><span class="comment">#将test_set按照batchsize处理为Dataloader，不进行数据重排</span></span><br><span class="line"></span><br><span class="line">model_best.<span class="built_in">eval</span>()</span><br><span class="line">prediction = []</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():<span class="comment">#当requires_grad设置为False时,反向传播时就不会自动求导了，因此大大节约了显存或者说内存</span></span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loader):</span><br><span class="line">        test_pred = model_best(data.cuda())</span><br><span class="line">        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=<span class="number">1</span>)</span><br><span class="line">        <span class="comment">#找到预测分类的最大值的索引</span></span><br><span class="line">        <span class="keyword">for</span> y <span class="keyword">in</span> test_label:</span><br><span class="line">            prediction.append(y)</span><br><span class="line"></span><br><span class="line"><span class="comment">#把結果写入 csv </span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;predict.csv&quot;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="string">&#x27;Id,Category\n&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i, y <span class="keyword">in</span>  <span class="built_in">enumerate</span>(prediction):</span><br><span class="line">        f.write(<span class="string">&#x27;&#123;&#125;,&#123;&#125;\n&#x27;</span>.<span class="built_in">format</span>(i, y))</span><br></pre></td></tr></table></figure>
<h3 id="4-结果分析与评估"><a href="#4-结果分析与评估" class="headerlink" title="4.结果分析与评估"></a>4.结果分析与评估</h3><h4 id="4-1-原始模型"><a href="#4-1-原始模型" class="headerlink" title="4.1 原始模型"></a>4.1 原始模型</h4><p>​    首先我们在CNN层数为10层(包括卷积层和池化层)的情况下进行训练，参数量统计信息如下所示，这里我们可以用torchsummary来对网络结构和参数进行统计。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torchsummary.summary(model, input_size, batch_size=-<span class="number">1</span>, device=<span class="string">&quot;cuda&quot;</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>model：pytorch 模型，必须继承自 nn.Module</li>
<li>input_size：模型输入 size，形状为 C，H ，W</li>
<li>batch_size：batch_size，默认为 -1，在展示模型每层输出的形状时显示的 batch_size</li>
<li>device：”cuda”或者”cpu”</li>
</ul>
</blockquote>
<p>​    下图为CNN神经网络的结构，并且可以从图中看出神经网络中的参数个数，我们可以先分析一下Conv2d-1层的参数量，可以看到共有1792个，其中在Conv2d-1层中，卷积核是$3\times3\times3$,共有64个filter，那么param的数量就是$3\times3\times3\times64+64$ 其中最后加入的64是偏置量。然后分析Conv2d-5，这里共有128个filter，输入深度是64的feature map，那么filter的深度也是64，那么param的数量就是$128\times3\times3\times64+128$,其中128是偏置量。</p>
<p><img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/image-20221122200209812.png" alt="image-20221122200209812"></p>
<p>​       在训练集上进行训练，epoch为30  ，可以看到第30轮的时候，在训练集上的准确率达到0.86，loss为0.003，但是在验证集上准确率只有0.64，loss为0.01。最终在训练集和验证集组合的训练集上训练，到第30轮准确率可以达到0.9，loss为0.002，可以看出该模型能在训练集上取得很好的训练效果，但是模型的泛化能力还需要增强。</p>
<p>​                                     <img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/image-20221122201550255.png" alt="image-20221122201550255" style="zoom: 80%;" /></p>
<p>​                                               <img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/7ICY@R%5$@3{HWXLAF8NCA8.png" alt="img"  /></p>
<p>​    使用原始版本的训练数据提交到ML2022springhw3的网站进行测试，测试结果基本在略高于0.75的水平</p>
<p><img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/image-20221207193528808.png" alt="image-20221207193528808"></p>
<h4 id="4-2-减少CNN深度"><a href="#4-2-减少CNN深度" class="headerlink" title="4.2 减少CNN深度"></a>4.2 减少CNN深度</h4><p>​    这里我们在参数量大体不变的情况下，将CNN结构的层数减半，然后我们对模型进行训练，比较和原始模型训练的效果。下图是CNN结构层数减半后的模型和对应的参数量（这里我们控制了在CNN结构中参数量大致相同）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">self.cnn = nn.Sequential(</span><br><span class="line">    nn.Conv2d(in_channels=<span class="number">3</span>, out_channels=<span class="number">256</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">    nn.BatchNorm2d(<span class="number">256</span>),<span class="comment"># 归一化处理,参数是</span></span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(kernel_size =<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>),   </span><br><span class="line">    <span class="comment">#由于padding了前后两列0，并且kernel大小为3，其实filter过滤后图片并无减小，减小只是在</span></span><br><span class="line">    <span class="comment">#maxpool池化，[256,64,64]64是filter，image-map</span></span><br><span class="line">    </span><br><span class="line">    </span><br><span class="line">    nn.Conv2d(<span class="number">256</span>,<span class="number">512</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>),</span><br><span class="line">    <span class="comment">#[256,64,64]这里我们取128个卷积核</span></span><br><span class="line">    nn.BatchNorm2d(<span class="number">512</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>,<span class="number">0</span>),</span><br><span class="line">    <span class="comment">#[512,32,32]</span></span><br><span class="line">    </span><br><span class="line">    nn.Conv2d(<span class="number">512</span>,<span class="number">512</span>,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>),</span><br><span class="line">    <span class="comment">#[512,32,32]这里我们取256个卷积核</span></span><br><span class="line">    nn.BatchNorm2d(<span class="number">512</span>),</span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.MaxPool2d(<span class="number">2</span>,<span class="number">2</span>,<span class="number">0</span>),</span><br><span class="line">    <span class="comment">#[512,16,16]</span></span><br><span class="line">    </span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/image-20221122220256012.png" alt="image-20221122220256012" style="zoom:80%;" /></p>
<p>​    通过模型训练我们可以发现，经过30个epoch训练后，不仅每个epoch的训练时间增加，并且在训练结果上也不如原有的模型，可以看到最终在训练集上的准确率只有0.73，而在验证集上的准确率只有0.55,通过比较我们可以得出结论，在参数量大致相同的情况下，使用更深层的神经网络对模型的训练结果会更好。</p>
<p><img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/image-20221122220718914.png" alt="image-20221122220718914" style="zoom:89%;" /></p>
<h4 id="4-3-评估data-normalization的影响"><a href="#4-3-评估data-normalization的影响" class="headerlink" title="4.3 评估data normalization的影响"></a>4.3 评估data normalization的影响</h4><p>​    下面是评估模型加入normalization过程对模型训练结果的影响，在之前的训练中，我们在CNN神经网络中加入了nn.BatchNorm2d对训练数据进行归一化处理，在下面的训练过程中，我们将不加入归一化语句对模型进行训练来比较data normalization对模型训练的影响。</p>
<p>​    通过训练我们可以发现，经过30个epoch后，在训练集上的准确率为0.89，在验证集上的准确率为0.58，虽然在训练集上的准确率略高于normalization的版本，但是在验证集上的准确率却明显低于normalization的版本。                                                                          </p>
<p><img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/image-20221123012025406.png" alt="image-20221123012025406"></p>
<p>​    Batch Normalization，简称BatchNorm或BN，翻译为“批归一化”，是神经网络中一种特殊的层，目前常见的结构是：卷积+BN+激活函数。归一化的一个显著的作用就是能够减少梯度消失问题，因为BN能够通过一定的规范化手段将每层神经网络任意神经元的输入值强行拉回到均值为0方差为1的范围里面，这样就能将输入值落在非线性函数比较敏感的区域中，这样就能避免梯度消失的问题，并且梯度越大还能加快学习效率。但是由训练我们可以看出在使用ReLU函数的情况下效果并不十分明显，因为ReLU函数本身就存在防止梯度消失的作用。</p>
<p>​    但是这里能够看出归一化对于防止过拟合方面的作用，因为BN的使用使得每一个minibatch中的样本都被关联在了一起，因此同样一个样本的输出不再仅仅取决于样本本身，也取决于同属一个batch的其他样本，而每次网络都是随机取batch，能够防止在一定程度上过拟合。</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1502.03167.pdf">1502.03167.pdf (arxiv.org)</a></p>
<h4 id="4-4-评估data-augmentation的影响"><a href="#4-4-评估data-augmentation的影响" class="headerlink" title="4.4 评估data augmentation的影响"></a>4.4 评估data augmentation的影响</h4><p>​    下面是评估data augmentation对实验结果的影响，在原始模型中我们使用了trainsform方法对数据进行data augmentation，transforms并不是直接扩充样本量，而是各种变换以一定的概率直接作用在原图片上，没有生成新样本，只不过在一次次的迭代过程中，各种随机变换随机发生，这样能使每一次epoch读进来的数据不同，从大数定理的角度相当于扩充了样本。</p>
<p><img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/image-20221123193435717.png" alt="image-20221123193435717"></p>
<p>​    经过了30个epoch的训练，我们可以从训练结果中看出，最终在Train set上的准确率达到了0.86，和原始模型相近，但在验证集上的准确率只达到了0.56，这里可以看到data augmentation在防止过拟合方面的作用，利用data augmentation，相当于增加了样本数据，能够让模型学到更好的学习泛化特征，从而能够减少过拟合现象。</p>
<h4 id="4-5-优化模型"><a href="#4-5-优化模型" class="headerlink" title="4.5 优化模型"></a>4.5 优化模型</h4><p>​    我们可以从训练数据中看到，最终经过30个epoch，在训练数据集上能够达到0.86的准确率，但在验证集上只能达到0.64。能够提升test集准确率的方法有如下几个方面：</p>
<p><img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/20200217224221982.png" alt="img" style="zoom:67%;" /></p>
<p>​    首先early stopping也就是提前让模型停下，防止训练过度情况的发生，也就是即便training set上的loss一直变低，只要validation set上的loss值开始出现增长时，就要提前结束训练。</p>
<p>​    在我们的训练实作中，我们可以通过选择适合的epoch来实现。当然我们也可以在pytorch中采用自动化的方式完成early stopping，early stopping的定义代码具体如下，第一个参数是patience，这个是当有连续的patience个轮次数值没有继续下降，反而上升的时候结束训练的条件，这里我们使用验证集上的准确率进行参照。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">early_stopping = EarlyStopping(patience, verbose=<span class="literal">True</span>)	</span><br><span class="line">......</span><br><span class="line">early_stopping(valid_loss, model)</span><br><span class="line"><span class="comment"># 若满足 early stopping 要求</span></span><br><span class="line"><span class="keyword">if</span> early_stopping.early_stop:</span><br><span class="line">	<span class="built_in">print</span>(<span class="string">&quot;Early stopping&quot;</span>)</span><br><span class="line">	<span class="comment"># 结束模型训练</span></span><br><span class="line">	<span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<p>​    第二点是regularization正则化，正则化的原理是给系数一些constrain，让它们不至于过大,从而防止过拟合现象的发生。</p>
<blockquote>
<p>ps：过拟合的时候，拟合函数的系数往往非常大，为什么？如下图所示，过拟合，就是拟合函数需要顾忌每一个点，最终形成的拟合函数波动很大。在某些很小的区间里，函数值的变化很剧烈。这就意味着函数在某些小区间里的导数值（绝对值）非常大，由于自变量值可大可小，所以只有系数足够大，才能保证导数值很大</p>
</blockquote>
<p>​    这一点在我们的实作中，可以通过修改优化器函数的参数来进行实现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.optim.Adam(params,lr,betas,eps,weight_decay)</span><br></pre></td></tr></table></figure>
<blockquote>
<ul>
<li>params (iterable) – 待优化参数的iterable或者是定义了参数组的dict</li>
<li>lr (<code>float</code>, 可选) – 学习率（默认：1e-3）</li>
<li>betas (Tuple[<code>float</code>, <code>float</code>], 可选) – 用于计算梯度以及梯度平方的运行平均值的系数（默认：0.9，0.999）</li>
<li>eps (<code>float</code>, 可选) – 为了增加数值计算的稳定性而加到分母里的项（默认：1e-8）</li>
<li>weight_decay (<code>float</code>, 可选) – 权重衰减（L2惩罚）（默认: 0）</li>
</ul>
</blockquote>
<p>​    另外一点是在加入Dropout层，Dropout层是让每一个Neuron有p%的概率被丢掉，那么丢掉以后和这个Neuron相连的weight也没用了，但是在testing的阶段，就不再使用dropout。dropout的原理是能够通过随机拆除神经元，等于在不同的模型上进行训练，最后再按加权进行平均处理，这样不仅能训练的更快，而且通常能够有更好的训练结果，另外由于随机性的存在，所有weight基本上都能够训练的到。<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/21d4c64fb8b5">Dropout作用原理 - 简书 (jianshu.com)</a></p>
<p><img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/2020021900205073.png" alt="img" style="zoom:67%;" /></p>
<p>​    在实作中可以通过加入dropout层实现</p>
<blockquote>
<p>CLASS torch.nn.Dropout(p=0.5, inplace=False)</p>
</blockquote>
<ul>
<li><strong>p</strong>：所有输入单元归零的概率，默认值是0.5</li>
<li><strong>inplace</strong>：表示是否进行覆盖运算。如果设置为True表示</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;# Model&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Classifier</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Classifier, self).__init__()</span><br><span class="line">        <span class="comment"># torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)</span></span><br><span class="line">        <span class="comment"># torch.nn.MaxPool2d(kernel_size, stride, padding)</span></span><br><span class="line">        <span class="comment"># input 維度 [3, 128, 128]</span></span><br><span class="line">        self.cnn = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),  <span class="comment"># [64, 128, 128]</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>),      <span class="comment"># [64, 64, 64]</span></span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="comment"># [128, 64, 64]</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">128</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>),      <span class="comment"># [128, 32, 32]</span></span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">128</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="comment"># [256, 32, 32]</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">256</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>),      <span class="comment"># [256, 16, 16]</span></span><br><span class="line"></span><br><span class="line">            nn.Conv2d(<span class="number">256</span>, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="comment"># [512, 16, 16]</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>),       <span class="comment"># [512, 8, 8]</span></span><br><span class="line">            </span><br><span class="line">            nn.Conv2d(<span class="number">512</span>, <span class="number">512</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>), <span class="comment"># [512, 8, 8]</span></span><br><span class="line">            nn.BatchNorm2d(<span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>),       <span class="comment"># [512, 4, 4]</span></span><br><span class="line">        )</span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(<span class="number">512</span>*<span class="number">4</span>*<span class="number">4</span>, <span class="number">4096</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dropout(<span class="number">0.2</span>),</span><br><span class="line">            nn.Linear(<span class="number">4096</span>, <span class="number">2048</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dropout(<span class="number">0.2</span>),</span><br><span class="line">            nn.Linear(<span class="number">2048</span>, <span class="number">1024</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">1024</span>, <span class="number">512</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">11</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = self.cnn(x)</span><br><span class="line">        out = out.view(out.size()[<span class="number">0</span>], -<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> self.fc(out)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;# Training</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">使用 training set 训练，使用 validation set 找好的参数</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">model = Classifier().cuda()</span><br><span class="line">loss = nn.CrossEntropyLoss() <span class="comment"># 因為、为是 classification task，所以 loss 使用 CrossEntropyLoss</span></span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">0.001</span>,weight_decay=<span class="number">1e-5</span>) <span class="comment"># optimizer 使用 Adam优化器</span></span><br><span class="line">num_epoch = <span class="number">70</span></span><br></pre></td></tr></table></figure>
<p>​    在加入了dropout层和正则化系数后，我们还加深了全连接网络的深度来获得更好的学习效果，可以从下面的训练情况中看出，在第30个epoch虽然训练集上的准确率只有0.73，但是验证集上的准确率已经达到了原始模型0.64的水准，说明了模型的泛化能力增强了，继续训练至60轮，在训练集上的准确率可达0.9，在验证集上也达到了0.70，但是在30轮之后，验证集上的准确率提升缓慢，说明模型已经达到了瓶颈，如果想达到更高，还需要进一步调整模型方案。</p>
<p><img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/image-20221124111932930.png" alt="image-20221124111932930" style="zoom:67%;" /></p>
<p>​    使用全部数据集对优化后的模型进行训练，尝试将数据集提交到ML2022hw3的网站进行测试，在epoch为70的情况下（训练时间在一个多小时），大概能够拿到80分左右的分数，相比于上面的原始模型还是有一定的提高的。</p>
<p><img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/image-20221207193344296.png" alt="image-20221207193344296"></p>
<h3 id="5-进阶"><a href="#5-进阶" class="headerlink" title="5.进阶"></a>5.进阶</h3><h4 id="5-1-Residual-Implementation"><a href="#5-1-Residual-Implementation" class="headerlink" title="5.1 Residual Implementation"></a>5.1 Residual Implementation</h4><p>​    上面我尝试了使用多种方式优化模型，在网上读论文发现对图像分类问题，有一种更好的方式为残差神经网络。首先介绍为什么要引入残差神经网络，在相同的优化条件下，更深神经网络的训练效果更强是十分显然的，然而由于参数过多、模型复杂度更高，深层神经网络会出现十分严重的过拟合问题，即训练集与测试集准确度之间的gap过大。</p>
<p>​    </p>
<p><img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/image-20221206170824779.png" alt="image-20221206170824779"></p>
<p>​        有些情况下更深层的神经网络远不如一些浅的神经网络，另外还会出现梯度消失/梯度爆炸的问题，上图中，56层的神经网络相比于20层，新增加的36层是对神经网络的“恶化，由此一个想法自然而然的产生：如果这36层神经网络是恒等映射（identity mapping），那么56层的神经网络不就和20层的一样好了吗？</p>
<p>​    如果这36层神经网络相比于恒等映射再好上那么一点点（更接近最优函数），那么不就起到了正优化的作用了吗？ResNet的insight由此诞生。假设某一层内，最优函数记为 H(x) ，那么我们所拟合的目标函数 F(x) 定义为 F(x):=H(x)−x ，函数 F(x) 被称为“残差函数”。这一做法基于最优函数和线性函数具有较高的相似性，极端来看，权重层（weight layer）已经收敛不再更新任何参数，“网络退化”说明F(x)通道向着变坏的方向迭代，而添加的恒等映射（Identity）仅复制上一层的输出特征，一定程度上阻碍了更坏的情况发生。</p>
<p><img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/dcad4778d61d4248b5ae0d094e803627.png" alt="在这里插入图片描述"></p>
<h5 id="5-1-1-版本一"><a href="#5-1-1-版本一" class="headerlink" title="5.1.1 版本一"></a>5.1.1 版本一</h5><p>​    首先我根据李宏毅老师ppt上的方式简单实现了一下残差神经网络，由于中间存在一个identity，因此这里重点是有恒等映射反馈的层上我们采用的filter数目和输入的channel的数目相等，这样才能在输出结果上加入恒等映射。</p>
<p><img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/image-20221207194841075.png" alt="image-20221207194841075"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Residual_Network</span>(nn.Module):</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="built_in">super</span>(Residual_Network, self).__init__()</span><br><span class="line">    </span><br><span class="line">    self.cnn_layer1 = nn.Sequential(</span><br><span class="line">        nn.Conv2d(<span class="number">3</span>, <span class="number">64</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">        nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">    )</span><br><span class="line">    <span class="comment">#[64,128,128]</span></span><br><span class="line">    self.cnn_layer2 = nn.Sequential(</span><br><span class="line">        nn.Conv2d(<span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">        nn.BatchNorm2d(<span class="number">64</span>),</span><br><span class="line">    )</span><br><span class="line">    <span class="comment">#[64,128,128]</span></span><br><span class="line"></span><br><span class="line">    self.cnn_layer3 = nn.Sequential(</span><br><span class="line">        nn.Conv2d(<span class="number">64</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>),</span><br><span class="line">        nn.BatchNorm2d(<span class="number">128</span>),</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    self.cnn_layer4 = nn.Sequential(</span><br><span class="line">        nn.Conv2d(<span class="number">128</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">        nn.BatchNorm2d(<span class="number">128</span>),</span><br><span class="line">    )</span><br><span class="line">    self.cnn_layer5 = nn.Sequential(</span><br><span class="line">        nn.Conv2d(<span class="number">128</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">1</span>),</span><br><span class="line">        nn.BatchNorm2d(<span class="number">256</span>),</span><br><span class="line">    )</span><br><span class="line">    self.cnn_layer6 = nn.Sequential(</span><br><span class="line">        nn.Conv2d(<span class="number">256</span>, <span class="number">256</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">        nn.BatchNorm2d(<span class="number">256</span>),</span><br><span class="line">    )</span><br><span class="line">    self.fc_layer = nn.Sequential(</span><br><span class="line">        nn.Linear(<span class="number">256</span>* <span class="number">32</span>* <span class="number">32</span>, <span class="number">256</span>),</span><br><span class="line">        nn.ReLU(),</span><br><span class="line">        nn.Linear(<span class="number">256</span>, <span class="number">11</span>)</span><br><span class="line">    )</span><br><span class="line">    self.relu = nn.ReLU()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">    <span class="comment"># input (x): [batch_size, 3, 128, 128]</span></span><br><span class="line">    <span class="comment"># output: [batch_size, 11]</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Extract features by convolutional layers.</span></span><br><span class="line">    <span class="comment"># 第一层不做残差连接</span></span><br><span class="line">    x1 = self.cnn_layer1(x)</span><br><span class="line">    x1 = self.relu(x1)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 第二层进行残差连接</span></span><br><span class="line">    Residual = x1 </span><br><span class="line">    x2 = self.cnn_layer2(x1)</span><br><span class="line">    <span class="comment"># 在通过激活函数之前进行残差连接</span></span><br><span class="line">    x2 = x2 + Residual</span><br><span class="line">    x2 = self.relu(x2)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 第三层不进行残差连接</span></span><br><span class="line">    x3 = self.cnn_layer3(x2)</span><br><span class="line">    x3 = self.relu(x3)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 第四层进行残差连接</span></span><br><span class="line">    Residual = x3</span><br><span class="line">    x4 = self.cnn_layer4(x3)</span><br><span class="line">    x4 = x4 + Residual</span><br><span class="line">    x4 = self.relu(x4)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 第五层不进行残差连接</span></span><br><span class="line">    x5 = self.cnn_layer5(x4)</span><br><span class="line">    x5 = self.relu(x5)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 第六层进行残差连接</span></span><br><span class="line">    Residual = x5</span><br><span class="line">    x6 = self.cnn_layer6(x5)</span><br><span class="line">    x6 = x6 + Residual</span><br><span class="line">    x6 = self.relu(x6)</span><br><span class="line">    <span class="comment"># The extracted feature map must be flatten before going to fully-connected layers.</span></span><br><span class="line">    xout = x6.flatten(<span class="number">1</span>)</span><br><span class="line">    <span class="comment"># The features are transformed by fully-connected layers to obtain the final logits.</span></span><br><span class="line">    xout = self.fc_layer(xout)</span><br><span class="line">    <span class="keyword">return</span> xout</span><br></pre></td></tr></table></figure>
<p>​    对这个残差神经网络进行测试，效果并不十分理想，可能是加入恒等映射的原因，一开始损失函数收敛的很慢，在100个epoch的训练情况下，准确率只能达到0.6，但是时间已经在3小时以上，模型的训练效率并不高。</p>
<h5 id="5-1-2-版本二"><a href="#5-1-2-版本二" class="headerlink" title="5.1.2 版本二"></a>5.1.2 版本二</h5><p>​    同时也尝试使用更加规范化的版本，通过先定义残差块，再堆叠残差块实现更加深层的残差神经网络，下面是训练60个epoch的具体效果，准确率能够达到0.7左右。</p>
<p>​    </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Residual_Block</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, ic, oc, stride=<span class="number">1</span></span>):</span><br><span class="line">        <span class="comment"># torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)</span></span><br><span class="line">        <span class="comment"># torch.nn.MaxPool2d(kernel_size, stride, padding)</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(ic, oc, kernel_size=<span class="number">3</span>, stride=stride, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(oc),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        self.conv2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(oc, oc, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>),</span><br><span class="line">            nn.BatchNorm2d(oc),</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        self.relu = nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">        self.downsample = <span class="literal">None</span></span><br><span class="line">        <span class="keyword">if</span> stride != <span class="number">1</span> <span class="keyword">or</span> (ic != oc):</span><br><span class="line">            self.downsample = nn.Sequential(</span><br><span class="line">                nn.Conv2d(ic, oc, kernel_size=<span class="number">1</span>, stride=stride),</span><br><span class="line">                nn.BatchNorm2d(oc),</span><br><span class="line">            )</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        residual = x</span><br><span class="line">        out = self.conv1(x)</span><br><span class="line">        out = self.conv2(out)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> self.downsample:</span><br><span class="line">            residual = self.downsample(x)</span><br><span class="line">            </span><br><span class="line">        out += residual</span><br><span class="line">        <span class="keyword">return</span> self.relu(out)</span><br><span class="line">        </span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Classifier</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, block, num_layers, num_classes=<span class="number">11</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.preconv = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">32</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>, bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">32</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        self.layer0 = self.make_residual(block, <span class="number">32</span>, <span class="number">64</span>,  num_layers[<span class="number">0</span>], stride=<span class="number">2</span>)</span><br><span class="line">        self.layer1 = self.make_residual(block, <span class="number">64</span>, <span class="number">128</span>, num_layers[<span class="number">1</span>], stride=<span class="number">2</span>)</span><br><span class="line">        self.layer2 = self.make_residual(block, <span class="number">128</span>, <span class="number">256</span>, num_layers[<span class="number">2</span>], stride=<span class="number">2</span>)</span><br><span class="line">        self.layer3 = self.make_residual(block, <span class="number">256</span>, <span class="number">512</span>, num_layers[<span class="number">3</span>], stride=<span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">#self.avgpool = nn.AvgPool2d(2)</span></span><br><span class="line">        </span><br><span class="line">        self.fc = nn.Sequential(            </span><br><span class="line">            nn.Dropout(<span class="number">0.4</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span>*<span class="number">4</span>*<span class="number">4</span>, <span class="number">512</span>),</span><br><span class="line">            nn.BatchNorm1d(<span class="number">512</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Dropout(<span class="number">0.2</span>),</span><br><span class="line">            nn.Linear(<span class="number">512</span>, <span class="number">11</span>),</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">make_residual</span>(<span class="params">self, block, ic, oc, num_layer, stride=<span class="number">1</span></span>):</span><br><span class="line">        layers = []</span><br><span class="line">        layers.append(block(ic, oc, stride))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, num_layer):</span><br><span class="line">            layers.append(block(oc, oc))</span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># [3, 128, 128]</span></span><br><span class="line">        out = self.preconv(x)  <span class="comment"># [32, 64, 64]</span></span><br><span class="line">        out = self.layer0(out) <span class="comment"># [64, 32, 32]</span></span><br><span class="line">        out = self.layer1(out) <span class="comment"># [128, 16, 16]</span></span><br><span class="line">        out = self.layer2(out) <span class="comment"># [256, 8, 8]</span></span><br><span class="line">        out = self.layer3(out) <span class="comment"># [512, 4, 4]</span></span><br><span class="line">        <span class="comment">#out = self.avgpool(out) # [512, 2, 2]</span></span><br><span class="line">        out = self.fc(out.view(out.size(<span class="number">0</span>), -<span class="number">1</span>)) </span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<p>​    这种方法结合下面的平均交叉熵函数，应该能够在训练上达到很好的效果，经过更多轮次的训练应该可以更好的效果，但是训练时间应该会比较长，由于这个月kaggle GPU的时间已经超过了限制，训练的效果还需要进行进一步的测试。</p>
<h4 id="5-2-平衡交叉熵函数-Focal-loss"><a href="#5-2-平衡交叉熵函数-Focal-loss" class="headerlink" title="5.2 平衡交叉熵函数(Focal loss)"></a>5.2 平衡交叉熵函数(Focal loss)</h4><p>​        在资料查阅的过程中,又学习到一种应用于图像领域解决数据不平衡问题的方法。对于传统的分类问题交叉熵函数如下</p>
<p><img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/image-20221206213439029.png" alt="image-20221206213439029"  /></p>
<p>​        我们考虑简单的二分类问题，损失函数可写成下面的形式，其中m为正样本数目，n为负样本数目，N为样本总数</p>
<p><img src="https://cdn.jsdelivr.net/gh/sdu-lzq/image_box@main/image_blog/image-20221206213528030.png" alt="image-20221206213528030"></p>
<p>​    当样本分布失衡时，就会造成损失函数L分布的倾斜，如m&lt;&lt;n时，就会使负样本在损失函数中占据主导地位，由于损失函数的倾斜，模型训练就会偏向，造成模型对少样本类别的性能比较差。那么为了解决这个问题，可以在损失函数中添加权重因子，如在上述的二分类问题中，我们就可以用下面方式添加权重参数：</p>
<script type="math/tex; mode=display">
\alpha \in[0,1]  和  1-\alpha \\

L=\frac{1}{N}\left(\sum_{y_{i}=1}^{m}-\alpha \log (\hat{p})+\sum_{y_{i}=0}^{n}-(1-\alpha) \log (1-\hat{p})\right)</script><p>​    其中$\frac{\alpha}{1-\alpha}=\frac{n}{m}$，也就是权重的大小根据正负样本的分布进行设置。</p>
<p>​    focal loss就是为了解决样本不均衡的问题，具体形式如下</p>
<script type="math/tex; mode=display">
L_{f l}=\left\{\begin{array}{ll}
-(1-\hat{p})^{\gamma} \log (\hat{p}) & \text { if } \mathrm{y}=1 \\
-\hat{p}^{\gamma} \log (1-\hat{p}) & \text { if } \mathrm{y}=0
\end{array}\right.</script><p>​     可将上式简化为下面的表达式，$L_{f l}=-\left(1-p_{t}\right)^{\gamma} \log \left(p_{t}\right)$反映了与ground truth即类别y的接近程度， pt 越大说明越接近类别y，即分类越准确。而$\gamma$为可调节因子，从上面式子可以看出，对于分类准确的样本，损失会变小，对于分类不准确的样本，损失基本没有改变，整体而言相当于增加了分类不准确样本的权重。</p>
<p>​     pt也反应了分类的难易程度， pt 越大，说明分类的置信度越高，代表样本越易分； pt 越小，分类的置信度越低，代表样本越难分。因此focal loss相当于增加了难分样本在损失函数的权重，使得损失函数倾向于难分的样本，有助于提高难分样本的准确度。</p>
<p>​    对于Focal loss，我们可以用下面的代码实现</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FocalLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, class_num, alpha=<span class="literal">None</span>, gamma=<span class="number">2</span>, size_average=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="keyword">if</span> alpha <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            self.alpha = Variable(torch.ones(class_num, <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(alpha, Variable):</span><br><span class="line">                self.alpha = alpha</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                self.alpha = Variable(alpha)</span><br><span class="line">        self.gamma = gamma</span><br><span class="line">        self.class_num = class_num</span><br><span class="line">        self.size_average = size_average</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, inputs, targets</span>):</span><br><span class="line">        N = inputs.size(<span class="number">0</span>)</span><br><span class="line">        C = inputs.size(<span class="number">1</span>)</span><br><span class="line">        P = F.softmax(inputs, dim=<span class="number">1</span>)</span><br><span class="line">        class_mask = inputs.data.new(N, C).fill_(<span class="number">0</span>)</span><br><span class="line">        class_mask = Variable(class_mask)</span><br><span class="line">        ids = targets.view(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        class_mask.scatter_(<span class="number">1</span>, ids.data, <span class="number">1.</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> inputs.is_cuda <span class="keyword">and</span> <span class="keyword">not</span> self.alpha.is_cuda:</span><br><span class="line">            self.alpha = self.alpha.cuda()</span><br><span class="line">        alpha = self.alpha[ids.data.view(-<span class="number">1</span>)]</span><br><span class="line">        probs = (P*class_mask).<span class="built_in">sum</span>(<span class="number">1</span>).view(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        log_p = probs.log()</span><br><span class="line">        </span><br><span class="line">        batch_loss = -alpha*(torch.<span class="built_in">pow</span>((<span class="number">1</span>-probs), self.gamma))*log_p</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> self.size_average:</span><br><span class="line">            loss = batch_loss.mean()</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            loss = batch_loss.<span class="built_in">sum</span>()</span><br><span class="line">            </span><br><span class="line">        <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>
<h4 id="5-3-增加数据增强方法"><a href="#5-3-增加数据增强方法" class="headerlink" title="5.3 增加数据增强方法"></a>5.3 增加数据增强方法</h4><p>​    在找资料的过程中，许多博主采用了多种数据增强的方式，据说这样效果比较好，但是增加数据增强的方式会大大增加训练模型的时间。如果把下面的数据增强方法全部加入的话，训练的时间将大大增加。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># training 時做 data augmentation</span></span><br><span class="line">train_transform = transforms.Compose([</span><br><span class="line">    transforms.ToPILImage(),</span><br><span class="line">    <span class="comment">#将张量转为PIL图片，由小数转为0-255之间的像素值</span></span><br><span class="line">    transforms.RandomHorizontalFlip(),<span class="comment">#随机将图片进行水平翻转</span></span><br><span class="line">    transforms.RandomVerticalFlip(p=<span class="number">1</span>),     <span class="comment"># 随机上下翻转</span></span><br><span class="line">    transforms.RandomGrayscale(<span class="number">0.5</span>), <span class="comment"># 随机灰度化</span></span><br><span class="line">    transforms.RandomRotation(degrees=(<span class="number">0</span>, <span class="number">180</span>)), <span class="comment"># 图像随机旋转</span></span><br><span class="line">    transforms.RandomSolarize(threshold=<span class="number">192.0</span>),<span class="comment">#通过反转阈值以上的所有像素值，以给定的概率随机对图像进行日光化</span></span><br><span class="line">    transforms.ColorJitter(brightness=<span class="number">.5</span>,hue=<span class="number">0.5</span>), <span class="comment"># 改变图像的亮度和饱和度</span></span><br><span class="line">    transforms.ToTensor(), <span class="comment">#将图片转成Tensor，并把数值normalize到[0,1](data normalization)</span></span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<h3 id="6-结论"><a href="#6-结论" class="headerlink" title="6.结论"></a>6.结论</h3><p>​    本次实验我们实现了CNN神经网络分类器，通过调整层数，使用不同的优化策略对模型进行训练，通过实作了解了pytorch实现CNN神经网络的方法。并能够计算参数量和传播维度，并比较了神经网络层数，data augmentation和normalization对训练结果的影响，并通过regularization和Dropout进一步对模型进行优化，更加深了对模型训练的理解。并且还进一步拓展图像处理网络，学习了残差神经网络和Focal loss等优化方法。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="http://example.com">Strider</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://example.com/2022/12/08/ML3/">http://example.com/2022/12/08/ML3/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%88%86%E7%B1%BB%E5%99%A8-CNN/">神经网络分类器 CNN</a></div><div class="post_share"><div class="addthis_inline_share_toolbox"></div><script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=null" async="async"></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/12/08/ML1/"><img class="prev-cover" src="https://images.pexels.com/photos/1428787/pexels-photo-1428787.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=1600" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">机器学习ML1</div></div></a></div><div class="next-post pull-right"><a href="/2022/12/08/%E5%9B%A0%E5%AD%90%E5%88%86%E8%A7%A3%E5%AE%9E%E7%8E%B0/"><img class="next-cover" src="https://images.pexels.com/photos/1271619/pexels-photo-1271619.jpeg?auto=compress&amp;cs=tinysrgb&amp;w=1600" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">因子分解实现</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/header.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Strider</div><div class="author-info__description">A blog</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">46</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">23</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">13</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/sdu-lzq"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://www.zhihu.com/people/can-55-47" target="_blank" title="知乎"><i class="fab fa-zhihu"></i></a><a class="social-icon" href="mailto:lc_lzq@qq.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="/1036472882" target="_blank" title="qq"><i class="QQ"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is Strider's Blog.You can find an interesting soul here.</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Catalog</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#CNN%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%88%86%E7%B1%BB%E5%99%A8"><span class="toc-text">CNN神经网络分类器</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%AE%9E%E9%AA%8C%E7%9B%AE%E7%9A%84"><span class="toc-text">1.实验目的</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E5%AE%9E%E9%AA%8C%E7%8E%AF%E5%A2%83"><span class="toc-text">2.实验环境</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%AE%9E%E9%AA%8C%E6%96%B9%E6%B3%95"><span class="toc-text">3.实验方法</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-text">3.1 预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#3-1-1-%E6%96%87%E4%BB%B6%E8%AF%BB%E5%8F%96"><span class="toc-text">3.1.1 文件读取</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-1-2-data-augmentation"><span class="toc-text">3.1.2 data augmentation</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-1-3-%E7%B1%BB%E5%9E%8B%E8%BD%AC%E5%8C%96"><span class="toc-text">3.1.3 类型转化</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%88%86%E7%B1%BB%E5%99%A8%E6%9E%B6%E6%9E%84"><span class="toc-text">3.2神经网络分类器架构</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#3-2-1-Convolution"><span class="toc-text">3.2.1 Convolution</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-2-2-Maxpooling"><span class="toc-text">3.2.2 Maxpooling</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-2-3-CNN%E5%AE%8C%E6%95%B4%E7%BB%93%E6%9E%84"><span class="toc-text">3.2.3 CNN完整结构</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-text">3.3 全连接神经网络</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#3-3-1-%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82"><span class="toc-text">3.3.1 全连接层</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-3-2-%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="toc-text">3.3.2 激活函数</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-3-3-%E5%AE%8C%E6%95%B4%E7%9A%84%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-text">3.3.3 完整的全连接神经网络</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-4-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-text">3.4 模型训练</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-5-%E7%BB%93%E6%9E%9C%E9%A2%84%E6%B5%8B"><span class="toc-text">3.5 结果预测</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90%E4%B8%8E%E8%AF%84%E4%BC%B0"><span class="toc-text">4.结果分析与评估</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-1-%E5%8E%9F%E5%A7%8B%E6%A8%A1%E5%9E%8B"><span class="toc-text">4.1 原始模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-%E5%87%8F%E5%B0%91CNN%E6%B7%B1%E5%BA%A6"><span class="toc-text">4.2 减少CNN深度</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-%E8%AF%84%E4%BC%B0data-normalization%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-text">4.3 评估data normalization的影响</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-4-%E8%AF%84%E4%BC%B0data-augmentation%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-text">4.4 评估data augmentation的影响</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-5-%E4%BC%98%E5%8C%96%E6%A8%A1%E5%9E%8B"><span class="toc-text">4.5 优化模型</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E8%BF%9B%E9%98%B6"><span class="toc-text">5.进阶</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-1-Residual-Implementation"><span class="toc-text">5.1 Residual Implementation</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#5-1-1-%E7%89%88%E6%9C%AC%E4%B8%80"><span class="toc-text">5.1.1 版本一</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#5-1-2-%E7%89%88%E6%9C%AC%E4%BA%8C"><span class="toc-text">5.1.2 版本二</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2-%E5%B9%B3%E8%A1%A1%E4%BA%A4%E5%8F%89%E7%86%B5%E5%87%BD%E6%95%B0-Focal-loss"><span class="toc-text">5.2 平衡交叉熵函数(Focal loss)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-%E5%A2%9E%E5%8A%A0%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95"><span class="toc-text">5.3 增加数据增强方法</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E7%BB%93%E8%AE%BA"><span class="toc-text">6.结论</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/06/01/Reverse7/" title="Reverse7"><img src="https://cdn.pixabay.com/photo/2023/05/14/19/42/sky-7993656_1280.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Reverse7"/></a><div class="content"><a class="title" href="/2023/06/01/Reverse7/" title="Reverse7">Reverse7</a><time datetime="2023-06-01T00:15:54.000Z" title="Created 2023-06-01 08:15:54">2023-06-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/18/Reverse6/" title="Reverse6"><img src="https://cdn.pixabay.com/photo/2023/05/04/02/24/bali-7969001_640.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Reverse6"/></a><div class="content"><a class="title" href="/2023/05/18/Reverse6/" title="Reverse6">Reverse6</a><time datetime="2023-05-18T00:28:06.000Z" title="Created 2023-05-18 08:28:06">2023-05-18</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/14/CSP/" title="CSP"><img src="https://i.loli.net/2020/05/01/gkihqEjXxJ5UZ1C.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CSP"/></a><div class="content"><a class="title" href="/2023/05/14/CSP/" title="CSP">CSP</a><time datetime="2023-05-14T03:00:50.000Z" title="Created 2023-05-14 11:00:50">2023-05-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/08/Reverse5/" title="Reverse5"><img src="https://cdn.pixabay.com/photo/2022/08/03/13/09/moon-7362632_640.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Reverse5"/></a><div class="content"><a class="title" href="/2023/05/08/Reverse5/" title="Reverse5">Reverse5</a><time datetime="2023-05-08T07:26:19.000Z" title="Created 2023-05-08 15:26:19">2023-05-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/06/OS/" title="OS"><img src="https://cdn.pixabay.com/photo/2023/04/30/12/15/rock-formations-7960445_640.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="OS"/></a><div class="content"><a class="title" href="/2023/05/06/OS/" title="OS">OS</a><time datetime="2023-05-06T11:29:07.000Z" title="Created 2023-05-06 19:29:07">2023-05-06</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By Strider</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between single-column and double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Search</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  Loading the Database</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="Search for Posts" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.min.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container').forEach(node => {
            if (node.hasAttribute('display')) {
              btf.wrap(node, 'div', { class: 'mathjax-overflow' })
            } else {
              btf.wrap(node, 'span', { class: 'mathjax-overflow' })
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script></div><script defer="defer" id="fluttering_ribbon" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-fluttering-ribbon.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = true;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>